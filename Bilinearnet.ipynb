{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bilinearnet.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aw8EeKsuA9F",
        "colab_type": "code",
        "outputId": "a184fa49-6cee-44b4-d348-4a4cd0509998",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        }
      },
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E: Package 'python-software-properties' has no installation candidate\n",
            "Selecting previously unselected package google-drive-ocamlfuse.\n",
            "(Reading database ... 130942 files and directories currently installed.)\n",
            "Preparing to unpack .../google-drive-ocamlfuse_0.7.6-0ubuntu1~ubuntu18.04.1_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.7.6-0ubuntu1~ubuntu18.04.1) ...\n",
            "Setting up google-drive-ocamlfuse (0.7.6-0ubuntu1~ubuntu18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xueIX7hJuJdR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive\n",
        "import os\n",
        "os.chdir(\"drive/ML/分类/\")\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leED-ejvukA0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from matplotlib import pyplot as plt\n",
        "images=[]\n",
        "labels=[]\n",
        "def read_image(imageName):\n",
        "    im = Image.open(imageName).convert('RGB')\n",
        "    data = np.array(im)\n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMvkHIgcukm5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 读取在words里面有几个文件夹\n",
        "text = os.listdir('./resize_data')\n",
        "# 把文件夹里面的图片和其对应的文件夹的名字也就是对应的字\n",
        "for textPath in text:\n",
        "    for fn in os.listdir(os.path.join('resize_data', textPath)):\n",
        "        if fn.endswith('.jpg'):\n",
        "            fd = os.path.join('./resize_data', textPath, fn)\n",
        "            images.append(read_image(fd))\n",
        "            labels.append(textPath)\n",
        "            \n",
        "X = np.array(images)\n",
        "y = np.array(list(map(int, labels))) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwe4kItLumNk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=30)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjObF78SuoDV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "from keras.utils import np_utils\n",
        "Y_train = np_utils.to_categorical(y_train, 8)\n",
        "Y_test = np_utils.to_categorical(y_test, 8)\n",
        "print(X_train.shape)\n",
        "print(Y_train.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PXZYamejqay",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as K\n",
        "def Precision(y_true, y_pred):\n",
        "    \"\"\"精确率\"\"\"\n",
        "    tp= K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))  # true positives\n",
        "    pp= K.sum(K.round(K.clip(y_pred, 0, 1))) # predicted positives\n",
        "    precision = tp/ (pp+ K.epsilon())\n",
        "    return precision\n",
        "    \n",
        "def Recall(y_true, y_pred):\n",
        "    \"\"\"召回率\"\"\"\n",
        "    tp = K.sum(K.round(K.clip(y_true * y_pred, 0, 1))) # true positives\n",
        "    pp = K.sum(K.round(K.clip(y_true, 0, 1))) # possible positives\n",
        "    recall = tp / (pp + K.epsilon())\n",
        "    return recall\n",
        " \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5hP9eNlusAb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.models import Sequential\n",
        "from keras.models import Model\n",
        "from keras.utils import np_utils\n",
        "from keras.layers import Convolution2D,Activation,MaxPooling2D,Flatten,Dense,Dropout,Input,Reshape,Lambda\n",
        "from keras import optimizers\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import backend as K\n",
        "from keras.utils import plot_model\n",
        "import numpy as np\n",
        "from keras.callbacks import ModelCheckpoint,EarlyStopping,LearningRateScheduler,ReduceLROnPlateau\n",
        " \n",
        "def sign_sqrt(x):\n",
        "    return K.sign(x) * K.sqrt(K.abs(x) + 1e-10)\n",
        "\n",
        "def l2_norm(x):\n",
        "    return K.l2_normalize(x, axis=-1)\n",
        "\n",
        "def batch_dot(cnn_ab):\n",
        "    return K.batch_dot(cnn_ab[0], cnn_ab[1], axes=[1, 1])\n",
        "\n",
        "def bilinearnet():\n",
        "    input_tensor = Input(shape=(224,224,3))\n",
        "    vgg16 = VGG16(weights='imagenet', include_top=False,input_tensor=input_tensor)\n",
        "#    conv2048 = Convolution2D(filters=2048,kernel_size=(3,3),)\n",
        "#    vgg16_add_conv_to_2048 = Model(inputs=input_tensor,outputs=)\n",
        "    resnet50 = ResNet50(weights='imagenet', include_top=False,input_tensor=input_tensor)\n",
        "    model_vgg16 = Model(inputs=input_tensor,outputs=vgg16.output)\n",
        "    model_resnet50 = Model(inputs=input_tensor,outputs=resnet50.output)\n",
        "    model_vgg16.compile(loss='categorical_crossentropy',optimizer='adam')\n",
        "    model_resnet50.compile(loss='categorical_crossentropy',optimizer='adam')\n",
        "    \n",
        "    resnet50_x = Reshape([model_resnet50.layers[-6].output_shape[1]*model_resnet50.layers[-6].output_shape[2],\n",
        "                          model_resnet50.layers[-6].output_shape[3]])(model_resnet50.layers[-6].output)\n",
        "    vgg16_x = Reshape([model_vgg16.layers[-1].output_shape[1]*model_vgg16.layers[-1].output_shape[2],\n",
        "                       model_vgg16.layers[-1].output_shape[3]])(model_vgg16.layers[-1].output)\n",
        "    \n",
        "    cnn_dot_out = Lambda(batch_dot)([vgg16_x,resnet50_x])\n",
        "    \n",
        "    sign_sqrt_out = Lambda(sign_sqrt)(cnn_dot_out)\n",
        "    l2_norm_out = Lambda(l2_norm)(sign_sqrt_out)\n",
        "    flatten = Flatten()(l2_norm_out)\n",
        "    dropout = Dropout(0.5)(flatten)\n",
        "    output = Dense(8, activation='softmax')(dropout)\n",
        "    \n",
        "    model = Model(input_tensor, output)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=optimizers.SGD(lr=1e-4, momentum=0.9, decay=1e-6),\n",
        "                  metrics=['accuracy'])\n",
        "    print(model.summary())\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHmoMNP2y5Tc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model=bilinearnet()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oV3kT7COzu-u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "model_checkpoint = ModelCheckpoint('Bilinearnet.h5', monitor='val_loss', verbose=1, save_best_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GOKex3MkaOR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history=model.fit(X_train, Y_train, batch_size=50, epochs=50, verbose=1,\n",
        "          validation_data=(X_test, Y_test),callbacks=[model_checkpoint])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3mZzVhrKUdN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(history.history.keys())\n",
        "\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lmz3q9CQ_p9K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "import time\n",
        "import sys\n",
        "import os\n",
        "import random\n",
        "import pickle\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import keras\n",
        "import keras.layers\n",
        "import keras.applications\n",
        "import keras.backend\n",
        "import keras.preprocessing.image\n",
        "import keras.utils\n",
        "import tensorflow as tf\n",
        "\n",
        "import cv2\n",
        "import PIL\n",
        "import PIL.Image\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.initializers import glorot_normal\n",
        "\n",
        "def outer_product(x):\n",
        "    \"\"\"\n",
        "    calculate outer-products of 2 tensors\n",
        "\n",
        "        args \n",
        "            x\n",
        "                list of 2 tensors\n",
        "                , assuming each of which has shape = (size_minibatch, total_pixels, size_filter)\n",
        "    \"\"\"\n",
        "    return keras.backend.batch_dot(\n",
        "                x[0]\n",
        "                , x[1]\n",
        "                , axes=[1,1]\n",
        "            ) / x[0].get_shape().as_list()[1] \n",
        "\n",
        "def signed_sqrt(x):\n",
        "    \"\"\"\n",
        "    calculate element-wise signed square root\n",
        "\n",
        "        args\n",
        "            x\n",
        "                a tensor\n",
        "    \"\"\"\n",
        "    return keras.backend.sign(x) * keras.backend.sqrt(keras.backend.abs(x) + 1e-9)\n",
        "\n",
        "def L2_norm(x, axis=-1):\n",
        "    \"\"\"\n",
        "    calculate L2-norm\n",
        "\n",
        "        args \n",
        "            x\n",
        "                a tensor\n",
        "    \"\"\"\n",
        "    return keras.backend.l2_normalize(x, axis=axis)\n",
        "\n",
        "\n",
        "def build_model(\n",
        "    size_heigth=224\n",
        "    ,size_width=224\n",
        "    ,no_class=8\n",
        "    ,no_last_layer_backbone=17\n",
        "    \n",
        "    ,name_optimizer=\"sgd\"\n",
        "    ,rate_learning=1.0\n",
        "    ,rate_decay_learning=0.0\n",
        "    ,rate_decay_weight=0.0\n",
        "    \n",
        "    ,name_initializer=\"glorot_normal\"\n",
        "    ,name_activation_logits=\"softmax\"\n",
        "    ,name_loss=\"categorical_crossentropy\"\n",
        "\n",
        "    ,flg_debug=False\n",
        "    ,**kwargs\n",
        "):\n",
        "    \n",
        "    keras.backend.clear_session()\n",
        "    \n",
        "    print(\"-------------------------------\")\n",
        "    print(\"parameters:\")\n",
        "    for key, val in locals().items():\n",
        "        if not val == None and not key == \"kwargs\":\n",
        "            print(\"\\t\", key, \"=\",  val)\n",
        "    print(\"-------------------------------\")\n",
        "    \n",
        "    ### \n",
        "    ### load pre-trained model\n",
        "    ###\n",
        "    tensor_input = keras.layers.Input(shape=[size_heigth,size_width,3])\n",
        "    model_detector = keras.applications.vgg16.VGG16(\n",
        "                            input_tensor=tensor_input\n",
        "                            , include_top=False\n",
        "                            , weights='imagenet'\n",
        "                        )\n",
        "    \n",
        "\n",
        "    ### \n",
        "    ### bi-linear pooling\n",
        "    ###\n",
        "\n",
        "    # extract features from detector\n",
        "    x_detector = model_detector.layers[no_last_layer_backbone].output\n",
        "    shape_detector = model_detector.layers[no_last_layer_backbone].output_shape\n",
        "    if flg_debug:\n",
        "        print(\"shape_detector : {}\".format(shape_detector))\n",
        "\n",
        "    # extract features from extractor , same with detector for symmetry DxD model\n",
        "    shape_extractor = shape_detector\n",
        "    x_extractor = x_detector\n",
        "    if flg_debug:\n",
        "        print(\"shape_extractor : {}\".format(shape_extractor))\n",
        "        \n",
        "    \n",
        "    # rehape to (minibatch_size, total_pixels, filter_size)\n",
        "    x_detector = keras.layers.Reshape(\n",
        "            [\n",
        "                shape_detector[1] * shape_detector[2] , shape_detector[-1]\n",
        "            ]\n",
        "        )(x_detector)\n",
        "    if flg_debug:\n",
        "        print(\"x_detector shape after rehsape ops : {}\".format(x_detector.shape))\n",
        "        \n",
        "    x_extractor = keras.layers.Reshape(\n",
        "            [\n",
        "                shape_extractor[1] * shape_extractor[2] , shape_extractor[-1]\n",
        "            ]\n",
        "        )(x_extractor)\n",
        "    if flg_debug:\n",
        "        print(\"x_extractor shape after rehsape ops : {}\".format(x_extractor.shape))\n",
        "        \n",
        "        \n",
        "    # outer products of features, output shape=(minibatch_size, filter_size_detector*filter_size_extractor)\n",
        "    x = keras.layers.Lambda(outer_product)(\n",
        "        [x_detector, x_extractor]\n",
        "    )\n",
        "    if flg_debug:\n",
        "        print(\"x shape after outer products ops : {}\".format(x.shape))\n",
        "        \n",
        "        \n",
        "    # rehape to (minibatch_size, filter_size_detector*filter_size_extractor)\n",
        "    x = keras.layers.Reshape([shape_detector[-1]*shape_extractor[-1]])(x)\n",
        "    if flg_debug:\n",
        "        print(\"x shape after rehsape ops : {}\".format(x.shape))\n",
        "        \n",
        "        \n",
        "    # signed square-root \n",
        "    x = keras.layers.Lambda(signed_sqrt)(x)\n",
        "    if flg_debug:\n",
        "        print(\"x shape after signed-square-root ops : {}\".format(x.shape))\n",
        "        \n",
        "    # L2 normalization\n",
        "    x = keras.layers.Lambda(L2_norm)(x)\n",
        "    if flg_debug:\n",
        "        print(\"x shape after L2-Normalization ops : {}\".format(x.shape))\n",
        "\n",
        "\n",
        "\n",
        "    ### \n",
        "    ### attach FC-Layer\n",
        "    ###\n",
        "\n",
        "    if name_initializer != None:\n",
        "            name_initializer = eval(name_initializer+\"()\")\n",
        "            \n",
        "    x = keras.layers.Dense(\n",
        "            units=no_class\n",
        "            ,kernel_regularizer=keras.regularizers.l2(rate_decay_weight)\n",
        "            ,kernel_initializer=name_initializer\n",
        "        )(x)\n",
        "    if flg_debug:\n",
        "        print(\"x shape after Dense ops : {}\".format(x.shape))\n",
        "    tensor_prediction = keras.layers.Activation(name_activation_logits)(x)\n",
        "    if flg_debug:\n",
        "        print(\"prediction shape : {}\".format(tensor_prediction.shape))\n",
        "\n",
        "        \n",
        "\n",
        "    ### \n",
        "    ### compile model\n",
        "    ###\n",
        "    model_bilinear = keras.models.Model(\n",
        "                        inputs=[tensor_input]\n",
        "                        , outputs=[tensor_prediction]\n",
        "                    )\n",
        "    \n",
        "    \n",
        "    # fix pre-trained weights\n",
        "    for layer in model_detector.layers:\n",
        "        layer.trainable = False\n",
        "        \n",
        "        \n",
        "    # define optimizers\n",
        "    opt_adam = keras.optimizers.adam(\n",
        "                    lr=rate_learning\n",
        "                    , decay=rate_decay_learning\n",
        "                )\n",
        "    opt_rms = keras.optimizers.RMSprop(\n",
        "                    lr=rate_learning\n",
        "                    , decay=rate_decay_learning\n",
        "                )\n",
        "    opt_sgd = keras.optimizers.SGD(\n",
        "                    lr=rate_learning\n",
        "                    , decay=rate_decay_learning\n",
        "                    , momentum=0.9\n",
        "                    , nesterov=False\n",
        "                )\n",
        "    optimizers ={\n",
        "        \"adam\":opt_adam\n",
        "        ,\"rmsprop\":opt_rms\n",
        "        ,\"sgd\":opt_sgd\n",
        "    }\n",
        "    \n",
        "    model_bilinear.compile(\n",
        "        loss=name_loss\n",
        "        , optimizer=optimizers[name_optimizer]\n",
        "        , metrics=[\"categorical_accuracy\"]\n",
        "    )\n",
        "    \n",
        "    \n",
        "    \n",
        "    if flg_debug:\n",
        "        model_bilinear.summary()\n",
        "    \n",
        "    return model_bilinear"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zwdbn6up_yL-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = build_model(\n",
        "            # number of output classes, 8 for CUB200\n",
        "            no_class = 8\n",
        "\n",
        "            # pretrained model specification, using VGG16\n",
        "            # \"block5_conv3 \"\n",
        "            ,no_last_layer_backbone = 17\n",
        "    \n",
        "            # training parametes\n",
        "            ,rate_learning=1.0\n",
        "            ,rate_decay_weight=1e-8\n",
        "    \n",
        "            ,flg_debug=True\n",
        "        )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RN0hZ1KAeGG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "model_checkpoint = ModelCheckpoint('vgg-Bilinearnet.h5', monitor='loss', verbose=1, save_best_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2W7lwdMeghBZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "86b1aeb3-2a8c-465a-b31b-614c76d33073"
      },
      "source": [
        "history=model.fit(X_train, Y_train, batch_size=50, epochs=50, verbose=1,\n",
        "          validation_data=(X_test, Y_test),callbacks=[model_checkpoint])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 3200 samples, validate on 800 samples\n",
            "Epoch 1/50\n",
            "3200/3200 [==============================] - 22s 7ms/step - loss: 0.3657 - categorical_accuracy: 0.8709 - val_loss: 0.4668 - val_categorical_accuracy: 0.8138\n",
            "\n",
            "Epoch 00001: loss improved from 0.36955 to 0.36575, saving model to vgg-Bilinearnet.h5\n",
            "Epoch 2/50\n",
            "3200/3200 [==============================] - 22s 7ms/step - loss: 0.3696 - categorical_accuracy: 0.8672 - val_loss: 0.4652 - val_categorical_accuracy: 0.8125\n",
            "\n",
            "Epoch 00002: loss did not improve from 0.36575\n",
            "Epoch 3/50\n",
            "3200/3200 [==============================] - 22s 7ms/step - loss: 0.3648 - categorical_accuracy: 0.8806 - val_loss: 0.4552 - val_categorical_accuracy: 0.8175\n",
            "\n",
            "Epoch 00003: loss improved from 0.36575 to 0.36476, saving model to vgg-Bilinearnet.h5\n",
            "Epoch 4/50\n",
            "3200/3200 [==============================] - 21s 7ms/step - loss: 0.3638 - categorical_accuracy: 0.8731 - val_loss: 0.4416 - val_categorical_accuracy: 0.8212\n",
            "\n",
            "Epoch 00004: loss improved from 0.36476 to 0.36381, saving model to vgg-Bilinearnet.h5\n",
            "Epoch 5/50\n",
            "3200/3200 [==============================] - 21s 7ms/step - loss: 0.3597 - categorical_accuracy: 0.8756 - val_loss: 0.4586 - val_categorical_accuracy: 0.8162\n",
            "\n",
            "Epoch 00005: loss improved from 0.36381 to 0.35968, saving model to vgg-Bilinearnet.h5\n",
            "Epoch 6/50\n",
            "3200/3200 [==============================] - 22s 7ms/step - loss: 0.3542 - categorical_accuracy: 0.8762 - val_loss: 0.4769 - val_categorical_accuracy: 0.8062\n",
            "\n",
            "Epoch 00006: loss improved from 0.35968 to 0.35418, saving model to vgg-Bilinearnet.h5\n",
            "Epoch 7/50\n",
            "3200/3200 [==============================] - 22s 7ms/step - loss: 0.3539 - categorical_accuracy: 0.8747 - val_loss: 0.4385 - val_categorical_accuracy: 0.8250\n",
            "\n",
            "Epoch 00007: loss improved from 0.35418 to 0.35390, saving model to vgg-Bilinearnet.h5\n",
            "Epoch 8/50\n",
            "3200/3200 [==============================] - 22s 7ms/step - loss: 0.3516 - categorical_accuracy: 0.8791 - val_loss: 0.4386 - val_categorical_accuracy: 0.8175\n",
            "\n",
            "Epoch 00008: loss improved from 0.35390 to 0.35162, saving model to vgg-Bilinearnet.h5\n",
            "Epoch 9/50\n",
            "3200/3200 [==============================] - 22s 7ms/step - loss: 0.3504 - categorical_accuracy: 0.8784 - val_loss: 0.4524 - val_categorical_accuracy: 0.8212\n",
            "\n",
            "Epoch 00009: loss improved from 0.35162 to 0.35042, saving model to vgg-Bilinearnet.h5\n",
            "Epoch 10/50\n",
            "3200/3200 [==============================] - 22s 7ms/step - loss: 0.3445 - categorical_accuracy: 0.8831 - val_loss: 0.4468 - val_categorical_accuracy: 0.8325\n",
            "\n",
            "Epoch 00010: loss improved from 0.35042 to 0.34451, saving model to vgg-Bilinearnet.h5\n",
            "Epoch 11/50\n",
            "3200/3200 [==============================] - 22s 7ms/step - loss: 0.3515 - categorical_accuracy: 0.8784 - val_loss: 0.4391 - val_categorical_accuracy: 0.8338\n",
            "\n",
            "Epoch 00011: loss did not improve from 0.34451\n",
            "Epoch 12/50\n",
            "3200/3200 [==============================] - 22s 7ms/step - loss: 0.3438 - categorical_accuracy: 0.8766 - val_loss: 0.4384 - val_categorical_accuracy: 0.8275\n",
            "\n",
            "Epoch 00012: loss improved from 0.34451 to 0.34383, saving model to vgg-Bilinearnet.h5\n",
            "Epoch 13/50\n",
            "3200/3200 [==============================] - 22s 7ms/step - loss: 0.3422 - categorical_accuracy: 0.8853 - val_loss: 0.4563 - val_categorical_accuracy: 0.8375\n",
            "\n",
            "Epoch 00013: loss improved from 0.34383 to 0.34221, saving model to vgg-Bilinearnet.h5\n",
            "Epoch 14/50\n",
            "3200/3200 [==============================] - 22s 7ms/step - loss: 0.3463 - categorical_accuracy: 0.8809 - val_loss: 0.4361 - val_categorical_accuracy: 0.8362\n",
            "\n",
            "Epoch 00014: loss did not improve from 0.34221\n",
            "Epoch 15/50\n",
            "3200/3200 [==============================] - 22s 7ms/step - loss: 0.3317 - categorical_accuracy: 0.8934 - val_loss: 0.4436 - val_categorical_accuracy: 0.8225\n",
            "\n",
            "Epoch 00015: loss improved from 0.34221 to 0.33166, saving model to vgg-Bilinearnet.h5\n",
            "Epoch 16/50\n",
            "3200/3200 [==============================] - 22s 7ms/step - loss: 0.3352 - categorical_accuracy: 0.8881 - val_loss: 0.4478 - val_categorical_accuracy: 0.8225\n",
            "\n",
            "Epoch 00016: loss did not improve from 0.33166\n",
            "Epoch 17/50\n",
            "3200/3200 [==============================] - 22s 7ms/step - loss: 0.3376 - categorical_accuracy: 0.8856 - val_loss: 0.4488 - val_categorical_accuracy: 0.8137\n",
            "\n",
            "Epoch 00017: loss did not improve from 0.33166\n",
            "Epoch 18/50\n",
            "3200/3200 [==============================] - 22s 7ms/step - loss: 0.3349 - categorical_accuracy: 0.8834 - val_loss: 0.4346 - val_categorical_accuracy: 0.8262\n",
            "\n",
            "Epoch 00018: loss did not improve from 0.33166\n",
            "Epoch 19/50\n",
            "3200/3200 [==============================] - 22s 7ms/step - loss: 0.3287 - categorical_accuracy: 0.8925 - val_loss: 0.4487 - val_categorical_accuracy: 0.8225\n",
            "\n",
            "Epoch 00019: loss improved from 0.33166 to 0.32869, saving model to vgg-Bilinearnet.h5\n",
            "Epoch 20/50\n",
            "3200/3200 [==============================] - 22s 7ms/step - loss: 0.3282 - categorical_accuracy: 0.8903 - val_loss: 0.4264 - val_categorical_accuracy: 0.8350\n",
            "\n",
            "Epoch 00020: loss improved from 0.32869 to 0.32820, saving model to vgg-Bilinearnet.h5\n",
            "Epoch 21/50\n",
            "3200/3200 [==============================] - 22s 7ms/step - loss: 0.3269 - categorical_accuracy: 0.8931 - val_loss: 0.5112 - val_categorical_accuracy: 0.8000\n",
            "\n",
            "Epoch 00021: loss improved from 0.32820 to 0.32687, saving model to vgg-Bilinearnet.h5\n",
            "Epoch 22/50\n",
            "3200/3200 [==============================] - 22s 7ms/step - loss: 0.3404 - categorical_accuracy: 0.8837 - val_loss: 0.4271 - val_categorical_accuracy: 0.8337\n",
            "\n",
            "Epoch 00022: loss did not improve from 0.32687\n",
            "Epoch 23/50\n",
            "3200/3200 [==============================] - 22s 7ms/step - loss: 0.3296 - categorical_accuracy: 0.8837 - val_loss: 0.4217 - val_categorical_accuracy: 0.8312\n",
            "\n",
            "Epoch 00023: loss did not improve from 0.32687\n",
            "Epoch 24/50\n",
            "3200/3200 [==============================] - 21s 7ms/step - loss: 0.3210 - categorical_accuracy: 0.8937 - val_loss: 0.4364 - val_categorical_accuracy: 0.8350\n",
            "\n",
            "Epoch 00024: loss improved from 0.32687 to 0.32101, saving model to vgg-Bilinearnet.h5\n",
            "Epoch 25/50\n",
            "3200/3200 [==============================] - 21s 7ms/step - loss: 0.3258 - categorical_accuracy: 0.8903 - val_loss: 0.4298 - val_categorical_accuracy: 0.8362\n",
            "\n",
            "Epoch 00025: loss did not improve from 0.32101\n",
            "Epoch 26/50\n",
            "3200/3200 [==============================] - 22s 7ms/step - loss: 0.3304 - categorical_accuracy: 0.8837 - val_loss: 0.4473 - val_categorical_accuracy: 0.8300\n",
            "\n",
            "Epoch 00026: loss did not improve from 0.32101\n",
            "Epoch 27/50\n",
            "3200/3200 [==============================] - 22s 7ms/step - loss: 0.3187 - categorical_accuracy: 0.8934 - val_loss: 0.4446 - val_categorical_accuracy: 0.8250\n",
            "\n",
            "Epoch 00027: loss improved from 0.32101 to 0.31869, saving model to vgg-Bilinearnet.h5\n",
            "Epoch 28/50\n",
            "3200/3200 [==============================] - 21s 7ms/step - loss: 0.3160 - categorical_accuracy: 0.8972 - val_loss: 0.4280 - val_categorical_accuracy: 0.8475\n",
            "\n",
            "Epoch 00028: loss improved from 0.31869 to 0.31604, saving model to vgg-Bilinearnet.h5\n",
            "Epoch 29/50\n",
            "3200/3200 [==============================] - 22s 7ms/step - loss: 0.3186 - categorical_accuracy: 0.8941 - val_loss: 0.4491 - val_categorical_accuracy: 0.8275\n",
            "\n",
            "Epoch 00029: loss did not improve from 0.31604\n",
            "Epoch 30/50\n",
            "3200/3200 [==============================] - 22s 7ms/step - loss: 0.3231 - categorical_accuracy: 0.8875 - val_loss: 0.4200 - val_categorical_accuracy: 0.8312\n",
            "\n",
            "Epoch 00030: loss did not improve from 0.31604\n",
            "Epoch 31/50\n",
            "3200/3200 [==============================] - 22s 7ms/step - loss: 0.3147 - categorical_accuracy: 0.8906 - val_loss: 0.4428 - val_categorical_accuracy: 0.8175\n",
            "\n",
            "Epoch 00031: loss improved from 0.31604 to 0.31465, saving model to vgg-Bilinearnet.h5\n",
            "Epoch 32/50\n",
            "3200/3200 [==============================] - 22s 7ms/step - loss: 0.3192 - categorical_accuracy: 0.8928 - val_loss: 0.4198 - val_categorical_accuracy: 0.8375\n",
            "\n",
            "Epoch 00032: loss did not improve from 0.31465\n",
            "Epoch 33/50\n",
            "3200/3200 [==============================] - 22s 7ms/step - loss: 0.3044 - categorical_accuracy: 0.8962 - val_loss: 0.4287 - val_categorical_accuracy: 0.8350\n",
            "\n",
            "Epoch 00033: loss improved from 0.31465 to 0.30435, saving model to vgg-Bilinearnet.h5\n",
            "Epoch 34/50\n",
            "3200/3200 [==============================] - 22s 7ms/step - loss: 0.3070 - categorical_accuracy: 0.8994 - val_loss: 0.4219 - val_categorical_accuracy: 0.8400\n",
            "\n",
            "Epoch 00034: loss did not improve from 0.30435\n",
            "Epoch 35/50\n",
            "3200/3200 [==============================] - 22s 7ms/step - loss: 0.3079 - categorical_accuracy: 0.8959 - val_loss: 0.4652 - val_categorical_accuracy: 0.8175\n",
            "\n",
            "Epoch 00035: loss did not improve from 0.30435\n",
            "Epoch 36/50\n",
            "3200/3200 [==============================] - 22s 7ms/step - loss: 0.3150 - categorical_accuracy: 0.8916 - val_loss: 0.4382 - val_categorical_accuracy: 0.8250\n",
            "\n",
            "Epoch 00036: loss did not improve from 0.30435\n",
            "Epoch 37/50\n",
            "3200/3200 [==============================] - 21s 7ms/step - loss: 0.3050 - categorical_accuracy: 0.8978 - val_loss: 0.4208 - val_categorical_accuracy: 0.8375\n",
            "\n",
            "Epoch 00037: loss did not improve from 0.30435\n",
            "Epoch 38/50\n",
            "3200/3200 [==============================] - 21s 7ms/step - loss: 0.3026 - categorical_accuracy: 0.9025 - val_loss: 0.4270 - val_categorical_accuracy: 0.8375\n",
            "\n",
            "Epoch 00038: loss improved from 0.30435 to 0.30263, saving model to vgg-Bilinearnet.h5\n",
            "Epoch 39/50\n",
            "3200/3200 [==============================] - 21s 7ms/step - loss: 0.2998 - categorical_accuracy: 0.9003 - val_loss: 0.4271 - val_categorical_accuracy: 0.8312\n",
            "\n",
            "Epoch 00039: loss improved from 0.30263 to 0.29976, saving model to vgg-Bilinearnet.h5\n",
            "Epoch 40/50\n",
            "3200/3200 [==============================] - 22s 7ms/step - loss: 0.3006 - categorical_accuracy: 0.8994 - val_loss: 0.4150 - val_categorical_accuracy: 0.8512\n",
            "\n",
            "Epoch 00040: loss did not improve from 0.29976\n",
            "Epoch 41/50\n",
            "3200/3200 [==============================] - 22s 7ms/step - loss: 0.3005 - categorical_accuracy: 0.9066 - val_loss: 0.4309 - val_categorical_accuracy: 0.8387\n",
            "\n",
            "Epoch 00041: loss did not improve from 0.29976\n",
            "Epoch 42/50\n",
            "3200/3200 [==============================] - 22s 7ms/step - loss: 0.2986 - categorical_accuracy: 0.9056 - val_loss: 0.4342 - val_categorical_accuracy: 0.8387\n",
            "\n",
            "Epoch 00042: loss improved from 0.29976 to 0.29860, saving model to vgg-Bilinearnet.h5\n",
            "Epoch 43/50\n",
            "3200/3200 [==============================] - 21s 7ms/step - loss: 0.2985 - categorical_accuracy: 0.9012 - val_loss: 0.4168 - val_categorical_accuracy: 0.8312\n",
            "\n",
            "Epoch 00043: loss improved from 0.29860 to 0.29850, saving model to vgg-Bilinearnet.h5\n",
            "Epoch 44/50\n",
            "3200/3200 [==============================] - 21s 7ms/step - loss: 0.2937 - categorical_accuracy: 0.9006 - val_loss: 0.4270 - val_categorical_accuracy: 0.8300\n",
            "\n",
            "Epoch 00044: loss improved from 0.29850 to 0.29374, saving model to vgg-Bilinearnet.h5\n",
            "Epoch 45/50\n",
            "3200/3200 [==============================] - 22s 7ms/step - loss: 0.2911 - categorical_accuracy: 0.9072 - val_loss: 0.4261 - val_categorical_accuracy: 0.8337\n",
            "\n",
            "Epoch 00045: loss improved from 0.29374 to 0.29106, saving model to vgg-Bilinearnet.h5\n",
            "Epoch 46/50\n",
            "3200/3200 [==============================] - 22s 7ms/step - loss: 0.2908 - categorical_accuracy: 0.9075 - val_loss: 0.4169 - val_categorical_accuracy: 0.8425\n",
            "\n",
            "Epoch 00046: loss improved from 0.29106 to 0.29079, saving model to vgg-Bilinearnet.h5\n",
            "Epoch 47/50\n",
            "3200/3200 [==============================] - 22s 7ms/step - loss: 0.2956 - categorical_accuracy: 0.9044 - val_loss: 0.4326 - val_categorical_accuracy: 0.8425\n",
            "\n",
            "Epoch 00047: loss did not improve from 0.29079\n",
            "Epoch 48/50\n",
            "3200/3200 [==============================] - 21s 7ms/step - loss: 0.2906 - categorical_accuracy: 0.9050 - val_loss: 0.4242 - val_categorical_accuracy: 0.8300\n",
            "\n",
            "Epoch 00048: loss improved from 0.29079 to 0.29061, saving model to vgg-Bilinearnet.h5\n",
            "Epoch 49/50\n",
            "3200/3200 [==============================] - 22s 7ms/step - loss: 0.2900 - categorical_accuracy: 0.9081 - val_loss: 0.4358 - val_categorical_accuracy: 0.8287\n",
            "\n",
            "Epoch 00049: loss improved from 0.29061 to 0.29004, saving model to vgg-Bilinearnet.h5\n",
            "Epoch 50/50\n",
            "3200/3200 [==============================] - 22s 7ms/step - loss: 0.2931 - categorical_accuracy: 0.9031 - val_loss: 0.4196 - val_categorical_accuracy: 0.8400\n",
            "\n",
            "Epoch 00050: loss did not improve from 0.29004\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HwarbEX4Ka0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# now all layers are trainable\n",
        "for layer in model.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "# change LR\n",
        "opt_sgd = keras.optimizers.SGD(\n",
        "                lr=1e-3\n",
        "                , decay=1e-9\n",
        "                , momentum=0.9\n",
        "                , nesterov=False\n",
        "            )\n",
        "model.compile(\n",
        "    loss=\"categorical_crossentropy\"\n",
        "    , optimizer=opt_sgd\n",
        "    , metrics=[\"categorical_accuracy\"]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmZHebhF-MUv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history=model.fit(X_train, Y_train, batch_size=50, epochs=100, verbose=1,\n",
        "          validation_data=(X_test, Y_test),callbacks=[model_checkpoint])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}